{"cells":[{"cell_type":"markdown","metadata":{"id":"KpGY-3PMmYkC"},"source":["# Notebook Set-Up"]},{"cell_type":"markdown","source":["## Install Dependencies"],"metadata":{"id":"t3xito-ud16i"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KV2b2zX9sfi3"},"outputs":[],"source":["import torchvision.transforms as transforms\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","from torchvision import *\n","from torch.utils.data import Dataset, DataLoader\n","from torch.autograd import Variable\n","\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","import time\n","import copy\n","import os\n","import csv\n","import time\n","import pandas as pd"]},{"cell_type":"markdown","source":["## Mount Google Drive"],"metadata":{"id":"-OOlcsYwd4Qr"}},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1898,"status":"ok","timestamp":1658871371452,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"},"user_tz":420},"id":"c7G7r_F_pVVH","outputId":"9426ceb6-8e04-4060-d9fe-ffbc4e7e5c3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## Set Hyperperameters"],"metadata":{"id":"rShb-X-YcaUi"}},{"cell_type":"code","source":["outModelName = 'jess_dev_multilabel_posture' # CHANGE THIS TO SET-UP NEW RESULTS AND CHECKPOINTS FILENAMES\n","experiment_type = 'train_model' # choose from ['train_model', 'transfer_model]\n","experiment_name = 'posture_motion'  # train_model options ['social','motion','posture','posture_motion']\n","                            # transfer_model options ['motion_to_social','posture_to_social','posture_motion_to_social','default_to_social']\n","\n","batch_size = 64\n","base_learning_rate = 1e-3\n","droprate = 0.1\n","max_epoch = 2\n","use_dropout = True # add dropout layers (check this is consistent w/ checkpoint model)\n","\n","best_accuracy = 0\n","start_epoch = 0  # start from epoch 0"],"metadata":{"id":"DWDywvBRcZum","executionInfo":{"status":"ok","timestamp":1658871371452,"user_tz":420,"elapsed":4,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["if experiment_type == 'train_model':\n","  use_checkpoint = False # use default Resnet-50 weights\n","  freeze_layers = False # gradient descent on all layers\n","elif experiment_type == 'transfer_model':\n","  use_checkpoint = True # use pretrained weights from 'checkpoint_t7'\n","  freeze_layers = True # freeze all but the output layer(s) (fc)\n","\n","if experiment_name == 'social':\n","  weights = 'social'\n","  dataset = 'social_interaction'\n","  labels = ['social_interaction']\n","elif experiment_name == 'motion':\n","  weights = 'motion'\n","  dataset = 'motion'\n","  labels = ['motion']\n","elif experiment_name == 'posture':\n","  weights = 'posture'\n","  dataset = 'posture'\n","  labels = ['posture']\n","elif experiment_name == 'posture_motion':\n","  weights = 'posture_motion'\n","  dataset = 'posture_motion'\n","  labels = ['posture','motion']\n","elif experiment_name == 'motion_to_social':\n","  weights = 'motion'\n","  dataset = 'social_interaction'\n","  labels = ['social_interaction']\n","elif experiment_name == 'posture_to_social':\n","  weights = 'posture'\n","  dataset = 'social_interaction'\n","  labels = ['social_interaction']\n","elif experiment_name == 'posture_motion_to_social':\n","  weights = 'posture_motion'\n","  dataset = 'social_interaction'\n","  labels = ['social_interaction']\n","elif experiment_name == 'default_to_social':\n","  weights = 'n/a'\n","  dataset = 'social_interaction'\n","  labels = ['social_interaction']\n","  use_checkpoint = False # use default Resnet-50 weights"],"metadata":{"id":"H_QvCXUMgIJx","executionInfo":{"status":"ok","timestamp":1658871371453,"user_tz":420,"elapsed":4,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-lc6Ht_zt1Vf"},"source":["## Set Directories"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"--er7B0qt0gC","executionInfo":{"status":"ok","timestamp":1658871371453,"user_tz":420,"elapsed":4,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"outputs":[],"source":["images_dir = '/content/drive/Shareddrives/NMA-DL/images/final_model/'\n","result_dir = '/content/drive/Shareddrives/NMA-DL/results/'\n","annotations_csv = '/content/drive/Shareddrives/NMA-DL/annotations/annotations.csv'\n","\n","if not os.path.exists(result_dir):\n","  os.makedirs(result_dir)\n","\n","# Social Interactions (with Duplicates)\n","social_interaction_dir = [images_dir + 'train_social_duplicates', images_dir + 'valid_social_duplicates', images_dir + 'test_social_duplicates']\n","social_interaction_checkpoint = result_dir + 'experiment1/social_interactions/07_25_2022/experiment1_social-interactions_duplicates_batchsize64_lre-3_dropout0.1_epochs400_checkpoint.t7'\n","\n","# Posture (no Duplicates)\n","posture_dir = [images_dir + 'train_posture_NOduplicates', images_dir + 'valid_posture_NOduplicates', images_dir + 'test_posture_NOduplicates']\n","posture_checkpoint = result_dir + 'experiment1/posture/experiment1_posture_NOduplicates_batchsize64_lre-3_dropout0.1_epochs200_checkpoint.t7'\n","\n","# Motion (no Duplicates)\n","motion_dir = [images_dir + 'train_motion_NOduplicates', images_dir + 'valid_motion_NOduplicates', images_dir + 'test_motion_NOduplicates']\n","motion_checkpoint = result_dir + 'experiment1/motion/experiment1_motion_NOduplicates_batchsize64_lre-3_dropout0.1_epochs200_checkpoint.t7'\n","\n","# Posture + Motion (Multi-Label)\n","posture_motion_dir = posture_dir\n","posture_motion_checkpoint = ''\n","\n","train_dir = eval(dataset + '_dir')[0]\n","val_dir = eval(dataset + '_dir')[1] \n","test_dir = eval(dataset + '_dir')[2]\n","checkpoint_t7 = eval(weights + '_checkpoint')"]},{"cell_type":"markdown","metadata":{"id":"IvjsX8Mcs684"},"source":["# Get Data and Annotations"]},{"cell_type":"markdown","source":["## Load Datasets using DataLoader"],"metadata":{"id":"pLRlhgai92jz"}},{"cell_type":"code","source":["class ImageFolderWithPaths(datasets.ImageFolder):\n","    \"\"\"Custom dataset that includes image file paths. Extends\n","    torchvision.datasets.ImageFolder\n","    \"\"\"\n","\n","    # override the __getitem__ method. this is the method that dataloader calls\n","    def __getitem__(self, index):\n","        # this is what ImageFolder normally returns \n","        dataset = super(ImageFolderWithPaths, self).__getitem__(index)\n","        # append the image file path\n","        return (dataset + (self.imgs[index][0],))"],"metadata":{"id":"X25gzUpX65Yo","executionInfo":{"status":"ok","timestamp":1658871371453,"user_tz":420,"elapsed":4,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","execution_count":46,"metadata":{"id":"LBjfC-D9jQRR","executionInfo":{"status":"ok","timestamp":1658871375476,"user_tz":420,"elapsed":4027,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"outputs":[],"source":["# Transform Properties\n","data_transforms = transforms.Compose([\n","            transforms.Resize((224,224)),\n","            transforms.RandomHorizontalFlip(p=0.5),\n","            transforms.ToTensor(),\n","            transforms.ColorJitter(brightness=0.5, hue=0.3),\n","            transforms.RandomGrayscale(p=0.5),\n","            transforms.RandomRotation(degrees=5),\n","            transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n","\n","# Load Data\n","train_dataset = ImageFolderWithPaths(train_dir, data_transforms)\n","val_dataset = ImageFolderWithPaths(val_dir, data_transforms)\n","test_dataset = ImageFolderWithPaths(test_dir,data_transforms)\n","\n","# Data Loaders\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"markdown","source":["## Load Annotations and Get Classes"],"metadata":{"id":"AGq6e7KO-J1S"}},{"cell_type":"code","source":["def classDictionary(label):\n","  '''Return a dictionary where keys = class and values = integer for the label'''\n","  keys = np.unique(np.array(os.listdir(eval(label + '_dir')[0])))\n","  keys = [key for key in keys if '.' not in key]\n","  values = np.arange(len(keys))\n","  return dict(zip(keys, values))\n","\n","def getLabelsFromPaths(paths, labels=['posture','motion','social_interaction']):\n","  '''Return a dictionary of keys equal to the input labels and values equal to \n","  the index of the classes in that label'''\n","  \n","  classes = {}\n","  exclude_inputs = []\n","  for label in labels:\n","\n","    # Get actions and classes corresponding to the label \n","    labelAnnotations = annotations[annotations['VerbType'] == label]\n","    labelClasses = eval('classes_' + label)\n","    \n","    values = []\n","    for path in paths:\n","      fileName = os.path.basename(path)\n","\n","      # Get actions corresponding to the label and file\n","      actions = list(labelAnnotations[labelAnnotations['fileName'] == fileName]['Action'])\n","\n","      # Remove actions not in label classes\n","      actions = [action for action in actions if action in labelClasses]\n","\n","      # If no action found, don't use that image. If more than one \n","      # action found, choose first value\n","      if len(actions)==0:\n","        action = -1\n","      else:\n","        action = labelClasses[actions[0]] # CAN CHANGE TO RANDOM CHOICE IF DUPLICATES\n","      \n","      values.append(action)\n","      \n","    # Exclude inputs with no class\n","    exclude_inputs = exclude_inputs + [index for (index, item) in enumerate(values) if item == -1]\n","    classes[label] = torch.tensor(values)\n","\n","  exclude_inputs = list(np.unique(exclude_inputs))\n","  include_inputs = [ind for ind in range(len(paths)) if ind not in exclude_inputs]\n","  return classes, include_inputs"],"metadata":{"id":"jL1RWp79Y6r5","executionInfo":{"status":"ok","timestamp":1658871375476,"user_tz":420,"elapsed":7,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# Load Annotations\n","annotations = pd.read_csv(annotations_csv)\n","annotations['Action'] = annotations['Action'].str.replace('/','-') # Fix jump/fall\n","\n","# Get Classes for Each Label\n","classes_motion = classDictionary('motion')\n","classes_posture = classDictionary('posture')\n","classes_social_interaction = classDictionary('social_interaction')\n","\n","# Create Label Dictionary\n","labelDictionary = {}\n","for label in labels:\n","  labelDictionary[label] = len(eval('classes_' + label))\n","labelDictionary\n","\n","print(f'Motion Classes ({len(classes_motion)}): {list(classes_motion.keys())}')\n","print(f'Posture Classes ({len(classes_posture)}): {list(classes_posture.keys())}')\n","print(f'Social Classes ({len(classes_social_interaction)}): {list(classes_social_interaction.keys())}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"chraAJl890NM","executionInfo":{"status":"ok","timestamp":1658871377541,"user_tz":420,"elapsed":2070,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}},"outputId":"3dbb7beb-617c-4484-d570-7c621ac4f33d"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Motion Classes (6): ['board', 'jump-fall', 'ride', 'run', 'still', 'walk']\n","Posture Classes (5): ['bend', 'crouch', 'lay', 'sit', 'stand']\n","Social Classes (13): ['act_on', 'carry', 'fistbump', 'handshake', 'highfive', 'hold_sb', 'hug', 'kiss', 'pat', 'point_sb', 'pull_sb_soft', 'thumbsup', 'wave']\n"]}]},{"cell_type":"markdown","metadata":{"id":"6HQ1GH0YupTM"},"source":["# Define Model"]},{"cell_type":"markdown","source":["## Define Custom Output and Dropout Layers"],"metadata":{"id":"jb4cLPT6DXiR"}},{"cell_type":"code","source":["# Get names of model layers with the exception of output layers\n","global layer_names\n","layer_names = []\n","for name, module in models.resnet50().named_children():\n","  layer_names.append(name)\n","layer_names = layer_names[:-1]"],"metadata":{"id":"LuOURKQEfIGm","executionInfo":{"status":"ok","timestamp":1658871378406,"user_tz":420,"elapsed":871,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["class resnetCustomOutput(nn.Module):\n","    def __init__(self, net, labelDictionary):\n","        super().__init__()\n","\n","        # Get input features from last layer\n","        in_features = getattr(net,list(net.named_children())[-1][0]).in_features\n","\n","        # Assign all layers but fc to new model\n","        for name, module in net.named_children():\n","          if 'fc' not in name:\n","            setattr(self, name, module)\n","        \n","        # Add new output layer(s) using labelDictionary {'label': num_classes}\n","        for label in labelDictionary:\n","          outputLayer = nn.Linear(in_features=in_features, out_features=labelDictionary[label])\n","          setattr(self, label, outputLayer)\n","\n","    def forward(self, x):\n","        # Forward pass of all network layers except the output layer(s)\n","        for name in layer_names:\n","          x = getattr(self, name)(x)\n","        \n","        x = torch.flatten(x, 1)\n","        \n","        # Get fully-connected outputs for each label in the model\n","        output = { }\n","        for label in labelDictionary:\n","          output[label] = getattr(self, label)(x)\n","\n","        return output"],"metadata":{"id":"C7VGSyUwOgS5","executionInfo":{"status":"ok","timestamp":1658871378406,"user_tz":420,"elapsed":5,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["def append_dropout(model, rate = droprate):\n","  '''Add dropout layer after each nn.Conv2d layer'''\n","  for name, module in model.named_children():\n","    if len(list(module.children())) > 0:\n","      append_dropout(module)\n","    if isinstance(module, nn.Conv2d):\n","      new = nn.Sequential(module, nn.Dropout2d(p=rate, inplace=True))\n","      setattr(model, name, new)"],"metadata":{"id":"TNpBOMiiz1KU","executionInfo":{"status":"ok","timestamp":1658871378406,"user_tz":420,"elapsed":4,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["def getLabelDictionaryFromCheckpoint(checkpoint):\n","  '''Looks at checkpoint file, compares to model layers and returns a\n","  labelDictionary {'label': num_classes} matching the checkpoint file'''\n","\n","  # Get output layer names\n","  checkpoint_output = []\n","  for key in list(checkpoint['state_dict'].keys()):\n","    checkpoint_key = key.split('.', 1)[0]\n","    if checkpoint_key not in layer_names:\n","      checkpoint_output.append(checkpoint_key)\n","  checkpoint_output = list(np.unique(checkpoint_output))\n","\n","  # Get output layer classes\n","  checkpoint_labelDictionary = {}\n","  for label in checkpoint_output:\n","    checkpoint_labelDictionary[label] = checkpoint['state_dict'][checkpoint_output[0] + '.weight'].shape[0]\n","  return checkpoint_labelDictionary"],"metadata":{"id":"M-KwFYLyYx1a","executionInfo":{"status":"ok","timestamp":1658871378406,"user_tz":420,"elapsed":4,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["## Define RESNET-50 with options (i.e. dropout, checkpoints, num_classes, freeze, multilabel)"],"metadata":{"id":"qb5A8kbA8Od4"}},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2275,"status":"ok","timestamp":1658871380677,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"},"user_tz":420},"id":"9sJVr2TSqskc","outputId":"6a6b109a-178b-4ee0-c6f7-cd6658362134"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["# Use pytorch models using pre-trained weights\n","net = models.resnet50(pretrained=True)\n","\n","# Add dropout layers after each Conv2d\n","if use_dropout:\n","  append_dropout(net)\n","\n","# If using pretrained weights from checkpoint file, load them\n","if use_checkpoint:\n","  checkpoint = torch.load(checkpoint_t7)\n","\n","  # Get labelDictionary {'label': num_classes} from state_dict()\n","  checkpoint_labelDictionary = getLabelDictionaryFromCheckpoint(checkpoint)\n","\n","  # Change model outputs to match pretrained model\n","  net = resnetCustomOutput(net, checkpoint_labelDictionary)\n","\n","  # Load checkpoints\n","  net.load_state_dict(checkpoint['state_dict'])\n","\n","# Change model outputs to match new model inputs\n","net = resnetCustomOutput(net, labelDictionary)\n","\n","# If freezing, freeze all but the output layer weights/biases\n","for name, param in net.named_parameters():\n","  if freeze_layers:\n","    if any(label in name for label in labelDictionary.keys()):\n","      param.requires_grad = True\n","    else:\n","      param.requires_grad = False\n","  else:\n","    param.requires_grad = True"]},{"cell_type":"markdown","source":["## Define Loss and Optimization Functions"],"metadata":{"id":"cV8-UxNm40u0"}},{"cell_type":"code","execution_count":54,"metadata":{"id":"PiucY-hRq4sM","executionInfo":{"status":"ok","timestamp":1658871380677,"user_tz":420,"elapsed":8,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=base_learning_rate, momentum=0.9, weight_decay=1e-4)"]},{"cell_type":"markdown","source":["## Define Training and Test Functions"],"metadata":{"id":"LuHSnpchA85C"}},{"cell_type":"code","source":["from sys import path_hooks\n","def train(net, epoch, labels):\n","  '''Train the model on the test set'''\n","  print('\\nEpoch: %d' % epoch)\n","  net.train()\n","\n","  train_loss = dict()\n","  correct = dict()\n","  total = dict()\n","  for label in labels:\n","    train_loss[label] = 0\n","    correct[label] = 0\n","    total[label] = 0\n","\n","  for batch_idx, (inputs, _, paths) in enumerate(train_dataloader):\n","    targets, include_inputs = getLabelsFromPaths(paths, labels)\n","\n","    optimizer.zero_grad()\n","\n","    inputs = Variable(inputs[include_inputs,:,:,:])\n","    for key in targets:\n","      targets[key] = Variable(targets[key][include_inputs])\n","\n","    outputs = net(inputs)\n","\n","    loss = 0\n","    for key in targets:\n","      loss += criterion(outputs[key], targets[key])\n","    \n","    loss.backward()\n","    optimizer.step()\n","\n","    for key in targets:\n","      train_loss[key] += loss.item()\n","      _, predicted = torch.max(outputs[key].data, 1)\n","      total[key] += targets[key].size(0)\n","      correct[key] += predicted.eq(targets[key].data).cpu().sum()\n","\n","      if batch_idx % 500 == 0:\n","        print(batch_idx, len(train_dataloader), key, 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","            % (train_loss[key]/(batch_idx+1), 100.*correct[key]/total[key], correct[key], total[key]))\n","\n","  accuracy = dict()\n","  for key in targets:\n","    accuracy[key] = 100.*correct[key]/total[key]\n","    accuracy[key] = accuracy[key].item()\n","    train_loss[key] = train_loss[key]/batch_idx\n","  # return (train_loss/batch_idx, 100.*correct/total)\n","  return (train_loss, accuracy, total)"],"metadata":{"id":"1S5rxaUblL1i","executionInfo":{"status":"ok","timestamp":1658871380677,"user_tz":420,"elapsed":7,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["def test(net, epoch, labels, outModelName):\n","  '''Test the model on the validation set'''\n","  global best_accuracy\n","  net.eval()\n","\n","  test_loss = dict()\n","  correct = dict()\n","  total = dict()\n","  for label in labels:\n","    test_loss[label] = 0\n","    correct[label] = 0\n","    total[label] = 0\n","\n","  with torch.no_grad():\n","    for batch_idx, (inputs, _, paths) in enumerate(val_dataloader):\n","      targets, include_inputs = getLabelsFromPaths(paths, labels)\n","      \n","      inputs = Variable(inputs[include_inputs,:,:,:])\n","      for key in targets:\n","        targets[key] = Variable(targets[key][include_inputs])\n","\n","      outputs = net(inputs)\n","\n","      loss = 0\n","      for key in targets:\n","        loss += criterion(outputs[key], targets[key])\n","\n","      for key in targets:\n","        test_loss[key] += loss.item()\n","        _, predicted = torch.max(outputs[key].data, 1)\n","        total[key] += targets[key].size(0)\n","        correct[key] += predicted.eq(targets[key].data).cpu().sum()\n","\n","        if batch_idx % 200 == 0:\n","          print(batch_idx, len(val_dataloader), key, 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","              % (test_loss[key]/(batch_idx+1), 100.*correct[key]/total[key], correct[key], total[key]))\n","\n","  # Save checkpoint\n","  key = list(outputs.keys())[0]\n","  accuracy = 100.*correct[key]/total[key]\n","  if accuracy > best_accuracy:\n","    best_accuracy = accuracy\n","    checkpoint(net, accuracy, epoch, outModelName)\n","\n","  accuracy = dict()\n","  for key in targets:\n","    accuracy[key] = 100.*correct[key]/total[key]\n","    accuracy[key] = accuracy[key].item()\n","    test_loss[key] = test_loss[key]/batch_idx\n","\n","  # return (test_loss/batch_idx, 100.*correct/total)\n","  return (test_loss, accuracy, total)"],"metadata":{"id":"iICT8Iy85L9a","executionInfo":{"status":"ok","timestamp":1658871380678,"user_tz":420,"elapsed":8,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["## Define Checkpoint and Learning Rate Adjustment"],"metadata":{"id":"IWCIbIOQI_iU"}},{"cell_type":"code","source":["checkpointName = result_dir + outModelName + '_checkpoint.t7'\n","\n","def checkpoint(model, acc, epoch, outModelName):\n","  '''Save check point'''\n","  print('Saving..')\n","  state = {\n","      'state_dict': model.state_dict(),\n","      'acc': acc,\n","      'epoch': epoch,\n","      'rng_state': torch.get_rng_state()\n","  }\n","  torch.save(state, checkpointName)\n","\n","def adjust_learning_rate(optimizer, epoch):\n","  '''Decrease the learning rate at 100 and 150 epoch'''\n","  lr = base_learning_rate\n","  # if epoch >= 100:\n","  #   lr /= 10\n","  for param_group in optimizer.param_groups:\n","    param_group['lr'] = lr"],"metadata":{"id":"DUFTV9VfHunK","executionInfo":{"status":"ok","timestamp":1658871380678,"user_tz":420,"elapsed":8,"user":{"displayName":"Jess Haley","userId":"07640705200895203304"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["# Train Model"],"metadata":{"id":"qco7zAUqOi1_"}},{"cell_type":"code","source":["logName = result_dir + outModelName + '_result.csv'\n","startTime = time.time()\n","\n","if not os.path.exists(logName):\n","  with open(logName, 'w') as logfile:\n","      logwriter = csv.writer(logfile, delimiter=',')\n","      logwriter.writerow(['epoch', 'train_loss', 'train_acc', 'test_loss', 'test_acc','time_elapsed','train_batch','test_batch'])\n","\n","for epoch in range(start_epoch, max_epoch):\n","  adjust_learning_rate(optimizer, epoch)\n","  train_loss, train_acc, train_batch = train(net, epoch, labels)\n","  test_loss, test_acc, test_batch = test(net, epoch, labels, outModelName)\n","  \n","  with open(logName, 'a') as logfile:\n","    logwriter = csv.writer(logfile, delimiter=',')\n","    time_elapsed = time.time() - startTime\n","    logwriter.writerow([epoch, train_loss, train_acc, test_loss, test_acc, time_elapsed, train_batch, test_batch])\n","  print(f'Epoch: {epoch} | train acc: {train_acc} | test acc: {test_acc} | time: {time_elapsed}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fpuqi1pkJJnH","outputId":"edfd3073-499a-4159-b97e-5a00519914c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch: 0\n","0 35 posture Loss: 3.574 | Acc: 16.129% (10/62)\n","0 35 motion Loss: 3.574 | Acc: 3.226% (2/62)\n"]}]},{"cell_type":"code","source":["train_loss"],"metadata":{"id":"euat3VSRyf3I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_acc"],"metadata":{"id":"ERK_szBxLXqp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_loss"],"metadata":{"id":"_LKrtkiUNH5H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_acc"],"metadata":{"id":"O1MtRszvNYf7"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"implement_resnet_multilabel.ipynb","provenance":[{"file_id":"1D2sGO5ETLRsQa-4ePQOEoUasymf7SztM","timestamp":1658762557015}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}