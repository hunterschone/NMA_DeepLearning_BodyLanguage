{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8980e882-1a43-44a5-ba6b-fd33b31ca50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torchvision.transforms as transforms\n",
    "#from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7a0be2e-4c8b-434d-a124-08c8b7a6b44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -> `Change runtime type.`  select `GPU` \n",
      "Random seed 2022 has been set.\n"
     ]
    }
   ],
   "source": [
    "#Define functions: set device (GPU | CPU) and Seed\n",
    "def set_device():\n",
    "  '''Set device to use GPU if possible, else use CPU'''\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "    print(\"WARNING: For this notebook to perform best, \"\n",
    "        \"if possible, in the menu under `Runtime` -> \"\n",
    "        \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)\n",
    "\n",
    "#Set Device and Seed\n",
    "device = set_device()\n",
    "set_seed(seed=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5180c7e8-51d8-45bd-952b-1dd84355006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get directories\n",
    "val_dir = './experiment1_valid_nma'\n",
    "train_dir = './experiment1_train_nma'\n",
    "test_dir = './experiment1_test_nma'\n",
    "result_dir = '../results'\n",
    "if not os.path.exists(result_dir):\n",
    "  os.makedirs(result_dir)\n",
    "\n",
    "checkpoint_dir = './checkpoint/'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "  os.makedirs(checkpoint_dir)\n",
    "\n",
    "#Set Hyperparameters\n",
    "batch_size = 128\n",
    "base_learning_rate = 1e-3\n",
    "best_accuracy = 0\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "max_epoch = 10\n",
    "use_cuda = torch.cuda.is_available()\n",
    "freeze_layers = True # freeze all but the output layer (fc)\n",
    "classes = np.unique(np.array(os.listdir(train_dir) + os.listdir(test_dir)))\n",
    "classes = classes[classes != '.DS_Store']\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f9a1946-b7de-4353-99c1-4d3c82a54bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Properties\n",
    "data_transforms = transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# Load Data\n",
    "train_dataset = datasets.ImageFolder(train_dir,data_transforms)\n",
    "val_dataset = datasets.ImageFolder(val_dir, data_transforms)\n",
    "test_dataset = datasets.ImageFolder(test_dir,data_transforms)\n",
    "\n",
    "# Data Loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True) # DONT NEED TO BATCH THE TEST SET\n",
    "\n",
    "# Check Train and Test Data Properties\n",
    "train_images, train_labels = next(iter(train_dataloader))\n",
    "val_images, val_labels = next(iter(val_dataloader)) \n",
    "test_images, test_labels = next(iter(test_dataloader)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91134671-43d4-4f43-9f51-3ab9b65ff500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pytorch models using pre-trained weights\n",
    "net = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "net.fc = nn.Linear(net.fc.in_features,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90fa4089-c3e0-427c-9f6e-5d8399c7c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Loss and Optimization Functions\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=base_learning_rate, momentum=0.9, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75d9e717-7b94-4abd-979b-8a41c6ee41d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training and test functions\n",
    "def train(net, epoch, use_cuda=True):\n",
    "  '''Train the model on the test set'''\n",
    "  print('\\nEpoch: %d' % epoch)\n",
    "  net.train()\n",
    "  train_loss = 0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for batch_idx, (inputs, targets) in enumerate(train_dataloader):\n",
    "    if use_cuda:\n",
    "      inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    inputs, targets = Variable(inputs), Variable(targets)\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss += loss.item()\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += targets.size(0)\n",
    "    correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "    if batch_idx % 500 == 0:\n",
    "      print(batch_idx, len(train_dataloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "          % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "  return (train_loss/batch_idx, 100.*correct/total)\n",
    "\n",
    "\n",
    "def test(net, epoch, outModelName, use_cuda=True):\n",
    "  '''Test the model on the validation set'''\n",
    "  global best_acc\n",
    "  net.eval()\n",
    "  test_loss, correct, total = 0, 0, 0\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(val_dataloader):\n",
    "      if use_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "      outputs = net(inputs)\n",
    "      loss = criterion(outputs, targets)\n",
    "\n",
    "      test_loss += loss.item()\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      total += targets.size(0)\n",
    "      correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "      if batch_idx % 200 == 0:\n",
    "        print(batch_idx, len(val_dataloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "  # Save checkpoint\n",
    "  accuracy = 100.*correct/total\n",
    "  if accuracy > best_accuracy:\n",
    "    best_accurary = accuracy\n",
    "    checkpoint(net, accuracy, epoch, outModelName)\n",
    "  return (test_loss/batch_idx, 100.*correct/total)\n",
    "\n",
    "#Define checkpoint and learning rate adjustment\n",
    "def checkpoint(model, acc, epoch, outModelName):\n",
    "  '''Save check point'''\n",
    "  print('Saving..')\n",
    "  state = {\n",
    "      'state_dict': model.state_dict(),\n",
    "      'acc': acc,\n",
    "      'epoch': epoch,\n",
    "      'rng_state': torch.get_rng_state()\n",
    "  }\n",
    "  if not os.path.isdir('checkpoint'):\n",
    "      os.mkdir('checkpoint')\n",
    "  torch.save(state, f'./checkpoint/{outModelName}.t7')\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "  '''Decrease the learning rate at 100 and 150 epoch'''\n",
    "  lr = base_learning_rate\n",
    "  if epoch <= 9 and lr > 0.1:\n",
    "    # warm-up training for large minibatch\n",
    "    lr = 0.1 + (base_learning_rate - 0.1) * epoch / 10.\n",
    "  if epoch >= 100:\n",
    "    lr /= 10\n",
    "  if epoch >= 150:\n",
    "    lr /= 10\n",
    "  for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1230833f-e0f1-40b2-9533-05e85eff9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.named_parameters():\n",
    "  if freeze_layers:\n",
    "    if 'fc' not in name:\n",
    "      param.requires_grad=False\n",
    "  else:\n",
    "    param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c72a8303-d53a-465d-829a-698d70618d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e41483234cc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0madjust_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, use_cuda=use_cuda)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutModelName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, use_cuda=use_cuda)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-c998a9b5bb7a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epoch, use_cuda)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "outModelName = 'pretrain'\n",
    "logName = result_dir + net.__class__.__name__ + '_' + outModelName + '.csv'\n",
    "\n",
    "if not os.path.exists(logName):\n",
    "  with open(logName, 'w') as logfile:\n",
    "      logwriter = csv.writer(logfile, delimiter=',')\n",
    "      logwriter.writerow(['epoch', 'train loss', 'train acc', 'test loss', 'test acc'])\n",
    "\n",
    "for epoch in range(start_epoch, max_epoch):\n",
    "  adjust_learning_rate(optimizer, epoch)\n",
    "  train_loss, train_acc = train(net, epoch)#, use_cuda=use_cuda)\n",
    "\n",
    "  test_loss, test_acc = test(net, epoch, outModelName)#, use_cuda=use_cuda)\n",
    "  \n",
    "  with open(logName, 'a') as logfile:\n",
    "    logwriter = csv.writer(logfile, delimiter=',')\n",
    "    logwriter.writerow([epoch, train_loss, train_acc.item(), test_loss, test_acc.item()])\n",
    "  print(f'Epoch: {epoch} | train acc: {train_acc} | test acc: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
